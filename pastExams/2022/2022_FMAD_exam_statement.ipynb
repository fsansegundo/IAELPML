{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5a8940",
   "metadata": {},
   "source": [
    "<img src='https://github.com/mbdfmad/fmad2223/raw/main/fig/vertical_COMILLAS_COLOR.jpg' style= 'width:70mm'>\n",
    "\n",
    "<h1 style='font-family: Optima;color:#ecac00'>\n",
    "Máster en Big Data. Tecnología y Analítica Avanzada (MBD).\n",
    "<a class=\"tocSkip\">\n",
    "</h1>\n",
    "\n",
    "<h1 style='font-family: Optima;color:#ecac00'>\n",
    "Fundamentos Matemáticos del Análisis de Datos (FMAD). 2022-2023.\n",
    "<a class=\"tocSkip\">\n",
    "</h1>\n",
    "\n",
    "<h1 style='font-family: Optima;color:#ecac00'>\n",
    "2022-10-17 Exam.\n",
    "<a class=\"tocSkip\">   \n",
    "</h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6efef2",
   "metadata": {},
   "source": [
    "<h1 style='font-family: Optima;color:red'>\n",
    "NOMBRE Y APELLIDO: \n",
    "</h1>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65620f4",
   "metadata": {},
   "source": [
    "# Instructions <a class=\"tocSkip\">\n",
    "\n",
    "+ The exam consists of a short Moodle quiz and a data analysis exercise described below in this notebook. You can access the quiz in this link:  \n",
    "    [https://sifo.comillas.edu/mod/quiz/view.php?id=2579775&forceview=1](https://sifo.comillas.edu/mod/quiz/view.php?id=2579775&forceview=1)  \n",
    "\n",
    "+ The exam quiz accounts for a 20% of the exam grade and the data analysis accounts for the remaining 80%. We recommend that you don't use more than 20-25 minutes for the quiz!\n",
    "\n",
    "+ All the questions in the exam have the same value.\n",
    "    \n",
    "+ During the exam you can use code fragments from the lectures, check your notes, go online to read documentation, etc. The only requirement is that the exam reflects your individual work.  \n",
    "    **Please take this as a warning: getting external help during the exam will not be tolerated and will have academic consequences beyond this exam.** \n",
    "    \n",
    "+ Use this notebook to answer the exam question. When you are done simply email the notebook with your answers to \n",
    "<a href=\"mailto:fsansegundo@comillas.edu?subject=FMAD exam submission\">fsansegundo@comillas.edu</a>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9098b79",
   "metadata": {},
   "source": [
    "# Introduction to the Data Set <a class=\"tocSkip\">\n",
    "    \n",
    "+ For this exam we will be using a data set containing information about crime rates in different communities of the US in 1990. This data set has been adapted for the exam, starting from a classical example frequently used for Machine Learning models. You can find more information about this data set and the meaning of the variable names in the following link (look for the *Attribute Information* section):\n",
    "\n",
    "  [https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime](https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime)  \n",
    "\n",
    "+ You can download the data set using this link:\n",
    "  \n",
    "    [crimes_exam_data.csv](https://gist.githubusercontent.com/fsansegundo/513d3468f832bf9c928bdb010230447b/raw/580a33130ad481aa9ec68f07225e7c8e19a5abbe/crimes_exam_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a45cc",
   "metadata": {},
   "source": [
    "# Preliminaries <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbddab71",
   "metadata": {},
   "source": [
    "+ We add here the import commands for the common data science libraries so you don't have to waste time importing them. **But we warned that you may need additional imports for some questions!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f19a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Data Science Libraries Import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scp\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45d9d4",
   "metadata": {},
   "source": [
    "+ Read the data file into a pandas `DataFrame` **called `crimes`**, which we will use for the rest of the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b68c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c484c7a",
   "metadata": {},
   "source": [
    "# Questions <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a033e",
   "metadata": {},
   "source": [
    "### Question 1:  <a class=\"tocSkip\">\n",
    "\n",
    "+ How many rows are there in the table? \n",
    "+ How many variables?    \n",
    "+ Which variable has the most missing data? \n",
    "    \n",
    "After answering this question **make sure to remove all rows containing missing data** from the table before proceeding to the next question.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae91896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4297032",
   "metadata": {},
   "source": [
    "### Question 2:  <a class=\"tocSkip\">\n",
    "\n",
    "+ Show the variables in the data set and their types. If there are categorical variables identify them and convert them to that type. \n",
    "    \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2713bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34267f26",
   "metadata": {},
   "source": [
    "### Question 3:  <a class=\"tocSkip\">\n",
    "\n",
    "+ For the variables \n",
    " ```    \n",
    " 'population', 'householdsize', 'pctUrban', 'medIncome', 'PctPopUnderPov', 'PopDens'   \n",
    " ```\n",
    " (copy and paste them!) do a basic numeric summary that contains their mean, median, quartiles, sd and range (min and max).  \n",
    " *Hint:* you can do this in a single table for all those variables. \n",
    "\n",
    "+ Make a *pairplot* for all these variables.    \n",
    "    \n",
    "**Answer:**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd1f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f7b0396",
   "metadata": {},
   "source": [
    "### Question 4:  <a class=\"tocSkip\">\n",
    "\n",
    "+ Create a new column called `houseSize` dividing (binning) `householdSize` in 8 levels, from 1 to 5.5 in increments of 0.5:  \n",
    "    $\\qquad\\qquad\\qquad\\qquad\\qquad (1, 1.5],\\quad (1.5, 2],\\,\\ldots\\,, (4.5, 5],\\quad (5, 5.5]$\n",
    "\n",
    "+ Make a *frequencies table* for `houseSize` containing the absolute and relative frequencies (in the same table). \n",
    "    \n",
    "+ Looking at the pair plot observe the distribution of `pctUrban`. Find the number of communities that are *not purely urban but also not purely rural*. That is, find the number of rows of the table where  `pctUrban` is *simultaneously* bigger than 10 and smaller than 90. **Discard these rows from the table, but keep the name `crimes` for the resulting table.**\n",
    "    \n",
    "+ **After doing that** create another column called `isUrban` with value `True` if `pctUrban` $\\geq 90$ and value `False` otherwise. Create a relative frequency table for `isUrban`.\n",
    "    \n",
    "\n",
    "\n",
    "**Answer:**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5df8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7b441e1",
   "metadata": {},
   "source": [
    "### Question 5:  <a class=\"tocSkip\">\n",
    "\n",
    "    \n",
    "+ Make a plot showing (in the same plot) a histogram and density curve for `householdSize`. For the histogram make sure to use the same bins that you used for creating `houseSize`\n",
    "    \n",
    "+ Make a boxplot of `medIncome`. How many outliers are there? What community corresponds to the first (smallest) and last outliers (use the `comunityname` variable to find out their names).  \n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29578bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8711622b",
   "metadata": {},
   "source": [
    "### Question 6:  <a class=\"tocSkip\">\n",
    "    \n",
    "    \n",
    "+ Find the total population for each state, adding up the observations in the table corresponding to that state. \n",
    "\n",
    "+ Create a new data set containing only the data corresponding to the five most populated states. Call that new data set `crimesTop5`.\n",
    "\n",
    "<hr style='border: 1px dashed blue'>\n",
    "    \n",
    "**Before going on:** make sure that you create a list called `top5names` with the names of the top 5 most populated states. For example, this could be \n",
    "```\n",
    "top5Names = ['DC', 'FL', 'PA', 'TX', 'FL']    \n",
    "```\n",
    "(but it is not! you have to find the real one)  Then, when you have created the list, run this code to remove the levels for the non top 5 states:\n",
    "```    \n",
    "top5_cat = pd.CategoricalDtype(top5Names)\n",
    "crimesTop5 = crimesTop5.copy()\n",
    "crimesTop5['state'] = crimesTop5.state.astype(top5_cat)    \n",
    "```    \n",
    "<hr style='border: 1px dashed blue'>    \n",
    "    \n",
    "+ After doing that, and using the data in `crimesTop5`, find the median by state of `ViolentCrimesPerPop`. Also choose a good plot to visualize the (possible) relation between these two variables.  \n",
    " **Optional:** Make a graphic judgment: does this relation depend on the `isUrban` variable?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274972e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ea44e3b",
   "metadata": {},
   "source": [
    "### Question 7:  <a class=\"tocSkip\">\n",
    "\n",
    "+ If we randomly pick a community whose `PopDens` is *below-average* (lower than the mean `PopDens` for all communities), find the probability `p` that  its `robbbPerPop` value is less than 30. \n",
    "    \n",
    "+ Using the previous result: suppose that we take a random sample (with replacement) of 15  *below-average* `PopDens` communities. What is the **theoretical** probability that **5 or more** of them will have a `robbbPerPop` value less than 30. \n",
    "\n",
    "+ Check that result using a simulation where you take $N = 10000$ samples, each of them with 15 *below-average* `PopDens` communities and find the relative frequency of the event:  5 or more of them have a `robbbPerPop` value less than 30.    \n",
    "    \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd307b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d52f6204",
   "metadata": {},
   "source": [
    "### Question 8:  <a class=\"tocSkip\">\n",
    "\n",
    "+ Using the whole `crimes` data set. Find the two states with the lowest and highest median values for `PctPopUnderPov`. Then find the two 95% confidence intervals for the means of `assaultPerPop` for each of these two states. What is your conclussion? \n",
    "    \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9cd93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30d8a0ef",
   "metadata": {},
   "source": [
    "### Question 9:  <a class=\"tocSkip\">\n",
    "\n",
    "+ Using the whole `crimes` data set. Find $\\mu_0$, the mean of `autoTheftPerPop` for those communities where `pctUrban < 10` (equivalently, `isUrban` is `False`). \n",
    "    \n",
    "+ Take a random sample (with replacement) of 30 communities with `pctUrban >= 90` (equivalently, `isUrban` is `True`) and use it to test (95% significance level) the **alternative hypothesis:** the mean `autoTheftPerPop` for urban communities is higher than $\\mu_0$. Make sure to set `random_state=2022` in the pandas `sample` method (or the equivalent `random.seed` if you use NumPy) to ensure the reproducibility of the sample. \n",
    "    \n",
    "+ **Optional:** consider the sample above as a *pilot study*. What sample size (number of communities) would you need to get 80% power in a test of the same hypothesis, if you want a precision $\\delta = 50$ with significance level equal = 95%.  \n",
    "\n",
    "**Answer:**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358428b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f637616",
   "metadata": {},
   "source": [
    "### Question 10:  <a class=\"tocSkip\">\n",
    "\n",
    "+ Consider only the  communities from the state of California (CA). Make a linear regression model for the variables:  \n",
    "  $x:$ `autoTheftPerPop`  \n",
    "  $y:$ `robbbPerPop`  \n",
    "     \n",
    "+ What percentage of variability in the response is explained by the model? \n",
    "+ What is the increment in `robbPerPop` for each unit increment in `autoTheftPerPop`?\n",
    "+ Make a scatter plot of these two variables along with the regression line. \n",
    "+ What is the predicted `robbPerPop` in a community with `autoTheftPerPop = 800`    \n",
    "+ What is the first residual of the model (the residual for the first observation)? \n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0fd67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
